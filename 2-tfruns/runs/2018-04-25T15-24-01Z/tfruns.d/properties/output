
> library(keras)

> # Data Preparation -----------------------------------------------------
> 
> batch_size <- 128

> num_classes <- 10

> epochs <- 6

> # Input image dimensions
> img_rows <- 28

> img_cols <- 28

> # The data, shuffled and split between train and test sets
> mnist <- dataset_mnist()

> x_train <- mnist$train$x

> y_train <- mnist$train$y

> x_test <- mnist$test$x

> y_test <- mnist$test$y

> # Redefine  dimension of train/test inputs
> x_train <- array_reshape(x_train, c(nrow(x_train), img_rows, img_cols, 1))

> x_test <- array_reshape(x_test, c(nrow(x_test), img_rows, img_cols, 1))

> input_shape <- c(img_rows, img_cols, 1)

> # Transform RGB values into [0,1] range
> x_train <- x_train / 255

> x_test <- x_test / 255

> cat('x_train_shape:', dim(x_train), '\n')
x_train_shape: 60000 28 28 1 

> cat(nrow(x_train), 'train samples\n')
60000 train samples

> cat(nrow(x_test), 'test samples\n')
10000 test samples

> # Convert class vectors to binary class matrices
> y_train <- to_categorical(y_train, num_classes)

> y_test <- to_categorical(y_test, num_classes)

> # Define Model -----------------------------------------------------------
> 
> model <- keras_model_sequential()

> model %>%
+   layer_conv_2d(filters = 16, kernel_size = c(3,3), activation = 'relu',
+                 input_shape = input_shape, name = "conv_1") % .... [TRUNCATED] 

> # Compile model
> model %>% compile(
+   loss = loss_categorical_crossentropy,
+   optimizer = optimizer_adadelta(),
+   metrics = c('accuracy')
+ )

> # Train & Evaluate -------------------------------------------------------
> 
> model %>% fit(
+   x_train, y_train,
+   batch_size = batch_size,
+  .... [TRUNCATED] 

> scores <- model %>% evaluate(
+   x_test, y_test, verbose = 0
+ )

> # Output metrics
> cat('Test loss:', scores[[1]], '\n')
Test loss: 0.02974771 

> cat('Test accuracy:', scores[[2]], '\n')
Test accuracy: 0.9903 
